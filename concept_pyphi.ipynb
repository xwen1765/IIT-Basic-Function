{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read EEG data   \n",
    "source localized    \n",
    "power would better to get neural info   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "[Errno 60] Operation timed out: '/Users/wenxuan/Library/CloudStorage/Dropbox/IIT project/sub_0010-mr_0015-ecr_echo1_EEG_pp.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/py3.9/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[39m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out: '/Users/wenxuan/Library/CloudStorage/Dropbox/IIT project/sub_0010-mr_0015-ecr_echo1_EEG_pp.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/wenxuan/Documents/Github/phi_calculation/concept_pyphi.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wenxuan/Documents/Github/phi_calculation/concept_pyphi.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/wenxuan/Documents/Github/phi_calculation/concept_pyphi.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mat \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mloadmat(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/wenxuan/Library/CloudStorage/Dropbox/IIT project/sub_0010-mr_0015-ecr_echo1_EEG_pp.mat\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wenxuan/Documents/Github/phi_calculation/concept_pyphi.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(mat[\u001b[39m\"\u001b[39m\u001b[39mEEG\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wenxuan/Documents/Github/phi_calculation/concept_pyphi.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m EEG \u001b[39m=\u001b[39m mat[\u001b[39m\"\u001b[39m\u001b[39mEEG\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py3.9/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:224\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m variable_names \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mvariable_names\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 224\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    225\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    226\u001b[0m     matfile_dict \u001b[39m=\u001b[39m MR\u001b[39m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py3.9/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py3.9/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[39m=\u001b[39m _open_file(file_like, appendmat, mode)\n\u001b[1;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[39myield\u001b[39;00m f\n",
      "File \u001b[0;32m/opt/miniconda3/envs/py3.9/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m appendmat \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_like\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mReader needs file name or open file-like object\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out: '/Users/wenxuan/Library/CloudStorage/Dropbox/IIT project/sub_0010-mr_0015-ecr_echo1_EEG_pp.mat'"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "mat = scipy.io.loadmat(\"/Users/wenxuan/Library/CloudStorage/Dropbox/IIT project/sub_0010-mr_0015-ecr_echo1_EEG_pp.mat\")\n",
    "print(mat[\"EEG\"][\"data\"][0][0].shape)\n",
    "EEG = mat[\"EEG\"][\"data\"][0][0]\n",
    "EEG_first_3_channels = EEG[:3, :10000]\n",
    "print(EEG_first_3_channels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to PyPhi!\n",
      "\n",
      "If you use PyPhi in your research, please cite the paper:\n",
      "\n",
      "  Mayner WGP, Marshall W, Albantakis L, Findlay G, Marchman R, Tononi G.\n",
      "  (2018). PyPhi: A toolbox for integrated information theory.\n",
      "  PLOS Computational Biology 14(7): e1006343.\n",
      "  https://doi.org/10.1371/journal.pcbi.1006343\n",
      "\n",
      "Documentation is available online (or with the built-in `help()` function):\n",
      "  https://pyphi.readthedocs.io\n",
      "\n",
      "To report issues, please use the issue tracker on the GitHub repository:\n",
      "  https://github.com/wmayner/pyphi\n",
      "\n",
      "For general discussion, you are welcome to join the pyphi-users group:\n",
      "  https://groups.google.com/forum/#!forum/pyphi-users\n",
      "\n",
      "To suppress this message, either:\n",
      "  - Set `WELCOME_OFF: true` in your `pyphi_config.yml` file, or\n",
      "  - Set the environment variable PYPHI_WELCOME_OFF to any value in your shell:\n",
      "        export PYPHI_WELCOME_OFF='yes'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyphi\n",
    "import numpy as np\n",
    "\n",
    "EEG_first_3_channels = np.array(EEG_first_3_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Z-score for each channel\n",
    "mean = np.mean(EEG_first_3_channels, axis=1)\n",
    "std = np.std(EEG_first_3_channels, axis=1)\n",
    "\n",
    "z_score = (EEG_first_3_channels - mean[:, np.newaxis]) / std[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score_binary = np.where(z_score > 0, 1, 0)\n",
    "z_score_binary.shape\n",
    "z_score_binary = np.transpose(z_score_binary)\n",
    "z_score_binary.shape\n",
    "len(z_score_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def tmp_generator(n):\n",
    "    results = np.zeros((2**n, n))\n",
    "    for i in range(2**n):\n",
    "        for j in range(n):\n",
    "            results[i, j] = i>>j & 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 1.],\n",
       "       [0., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_generator(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A discrete dynamical system is completely specified by its transition probability\n",
    "matrix (TPM)\n",
    "\n",
    "1) count each time one of the four states occurs and then compute their relative frequency. \n",
    "2) create a track record of what state occurs immediately after you took record of a state. Here, too, you want to compute frequencies (i.e., for each time that state 0 0 occurs, how often was the next state 0 0 again? How often was it 0 1? 1 0? And so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_states(data, states):\n",
    "    count = np.zeros(len(states))\n",
    "    for i in range(len(states)):\n",
    "        state = states[i]\n",
    "        count[i] = np.sum(np.all(data == state, axis=1))\n",
    "    total = np.sum(count)\n",
    "    frequency = count / total\n",
    "    return count, frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/wenxuan/Documents/Github/phi_calculation/eeg_pyphi.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/wenxuan/Documents/Github/phi_calculation/eeg_pyphi.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m count, frequency \u001b[39m=\u001b[39m count_states(z_score_binary, tmp_generator(\u001b[39m3\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wenxuan/Documents/Github/phi_calculation/eeg_pyphi.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(count)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wenxuan/Documents/Github/phi_calculation/eeg_pyphi.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(frequency)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_states' is not defined"
     ]
    }
   ],
   "source": [
    "count, frequency = count_states(z_score_binary, tmp_generator(3))\n",
    "print(count)\n",
    "print(frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_and_frequency_of_state_transitions(data, states):\n",
    "    \"\"\"\n",
    "    Calculates the state transition matrix and frequency of state transitions from the preprocessed EEG signal and possible binary combinations of states of nodes.\n",
    "\n",
    "    Parameters:\n",
    "        data (list): List of preprocessed EEG signal data points representing the state transitions of the nodes.\n",
    "        states (list): List of all possible binary combinations of states of nodes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two numpy arrays, the transition matrix and the frequency of state transitions between the binary combinations of states of nodes.\n",
    "\n",
    "    \"\"\"\n",
    "    transition_matrix = np.zeros((len(states),len(states)))\n",
    "    for i in range(len(data)-1):\n",
    "        current_state = data[i]\n",
    "        next_state = data[i + 1]\n",
    "        current_state_index = np.where((states == current_state).all(axis=1))[0][0]\n",
    "        next_state_index = np.where((states == next_state).all(axis=1))[0][0]\n",
    "        transition_matrix[current_state_index, next_state_index] += 1\n",
    "    frequency = transition_matrix / np.sum(transition_matrix, axis=1, keepdims=True)\n",
    "\n",
    "    # to avoid 1/0 = nan problem, assign as 0 or average probability if it nan\n",
    "    # average = 1 / len(states)\n",
    "    average = 0\n",
    "    frequency[np.isnan(frequency)] = average\n",
    "    return transition_matrix, frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " ...\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate \n",
    "transition_matrix, frequency = count_and_frequency_of_state_transitions(z_score_binary, tmp_generator(3))\n",
    "sbn_tpm = pyphi.convert.state_by_state2state_by_node(frequency)\n",
    "sbs_tpm = pyphi.convert.state_by_node2state_by_state(sbn_tpm)\n",
    "print(z_score_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "    network = pyphi.Network(sbs_tpm)\n",
    "    state = (1, 0, 0)\n",
    "    subsystem = pyphi.Subsystem(network, state)\n",
    "    result = pyphi.compute.phi(subsystem)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2.],\n",
       "       [0., 0., 0.],\n",
       "       [3., 0., 5.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ABC = np.array([[1,0,1,0,1,0],\n",
    "[1,1,1,1,1,1],\n",
    "[0,0,0,0,0,0]])\n",
    "\n",
    "def count_consecutive_zero_pairs(A):\n",
    "    \"\"\"\n",
    "    Given Data Matrix A (n x t, n = # of nodes, t = time points)\n",
    "    returns Matrix Result (n x n, n = # of nodes)\n",
    "    Each value in result represents: when time = t, if value of certain s = 0, then number of 0s at time = t+1, for each possible states S\n",
    "    for example, if n = 3 (S = {A, B, C}), then value at position [0,0] represent when time = t, number of 0s of A at time t+1 \n",
    "\n",
    "    Example:\n",
    "    ABC = np.array(\n",
    "        [[1,0,1,0,1,0],\n",
    "        [1,1,1,1,1,1],\n",
    "        [0,0,0,0,0,0]])\n",
    "    Result = array(\n",
    "        [[0., 0., 2.],\n",
    "        [0., 0., 0.],\n",
    "        [3., 0., 5.]])\n",
    "    \"\"\"\n",
    "    result = np.zeros((len(A), len(A)))\n",
    "    for i in range(len(A)):\n",
    "        for k in range(len(A)):\n",
    "            count = 0\n",
    "            for j in range(len(A[0])-1):\n",
    "                if ABC[i, j] == 0:\n",
    "                    if ABC[k, j+1] == 0:\n",
    "                        count = count + 1\n",
    "            result[i, k] = count\n",
    "    return result\n",
    "\n",
    "count_consecutive_zero_pairs(ABC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, (0.0, 0.0, 0.0)), 2),\n",
       " ((0, (0.0, 0.0, 1.0)), 2),\n",
       " ((0, (0.0, 1.0, 0.0)), 2),\n",
       " ((0, (0.0, 1.0, 1.0)), 0),\n",
       " ((0, (1.0, 0.0, 0.0)), 0),\n",
       " ((0, (1.0, 0.0, 1.0)), 0),\n",
       " ((0, (1.0, 1.0, 0.0)), 1),\n",
       " ((0, (1.0, 1.0, 1.0)), 1),\n",
       " ((1, (0.0, 0.0, 0.0)), 2),\n",
       " ((1, (0.0, 0.0, 1.0)), 1),\n",
       " ((1, (0.0, 1.0, 0.0)), 2),\n",
       " ((1, (0.0, 1.0, 1.0)), 0),\n",
       " ((1, (1.0, 0.0, 0.0)), 0),\n",
       " ((1, (1.0, 0.0, 1.0)), 0),\n",
       " ((1, (1.0, 1.0, 0.0)), 1),\n",
       " ((1, (1.0, 1.0, 1.0)), 1),\n",
       " ((2, (0.0, 0.0, 0.0)), 2),\n",
       " ((2, (0.0, 0.0, 1.0)), 2),\n",
       " ((2, (0.0, 1.0, 0.0)), 1),\n",
       " ((2, (0.0, 1.0, 1.0)), 0),\n",
       " ((2, (1.0, 0.0, 0.0)), 0),\n",
       " ((2, (1.0, 0.0, 1.0)), 0),\n",
       " ((2, (1.0, 1.0, 0.0)), 1),\n",
       " ((2, (1.0, 1.0, 1.0)), 1)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_S0_at_tplus1(matrix, condition_value):\n",
    "    '''\n",
    "    Calculate Conditional Probability of P(A | s)\n",
    "    '''\n",
    "    # Initialize a dictionary to store counts for each possible state S\n",
    "    counts = {}\n",
    "    \n",
    "    # Get the number of states\n",
    "    num_nodes = matrix.shape[0]\n",
    "    possible_states = tmp_generator(num_nodes)\n",
    "    num_possible_states = possible_states.shape[0]\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_possible_states):\n",
    "            counts[(i, tuple(possible_states[j]))] = 0\n",
    "\n",
    "    # Iterate over each time step t\n",
    "    for t in range(matrix.shape[1] - 1):\n",
    "        # Get the states at time t and t+1\n",
    "        S_t = tuple(matrix[:, t])\n",
    "        S_tplus1 = tuple(matrix[:, t+1])\n",
    "\n",
    "        # Iterate over each state index i and count the number of times each possible state has a value of 0 for state i in the following time step\n",
    "        for i in range(num_nodes):\n",
    "            if S_t[i] == condition_value:\n",
    "                index = np.where((possible_states == S_tplus1).all(axis=1))[0][0]\n",
    "                counts[(i, tuple(S_tplus1))] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "ABC = np.array([[1,0,1,0,1,0,0,0,0,0,0,0],\n",
    "[0,0,1,0,1,0,0,1,0,1,0,0],\n",
    "[1,0,0,0,1,0,1,0,0,0,1,0]])\n",
    "\n",
    "sorted(count_S0_at_tplus1(ABC, 0).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_conditional_prob_distribution(frequency_dict, condition):\n",
    "    # Calculate P(AB | A = 0)\n",
    "    counts = {}\n",
    "    total_count = 0\n",
    "\n",
    "    for k, v in frequency_dict.items():\n",
    "        if k[0] == condition:\n",
    "            counts[k[1]] = counts.get(k[1], 0) + v\n",
    "            total_count += v\n",
    "\n",
    "    probabilities_dict = {k: v / total_count for k, v in counts.items()}\n",
    "    prob_array = np.array(list(probabilities_dict.values()))\n",
    "\n",
    "    return probabilities_dict, prob_array\n",
    "\n",
    "def calculate_conditional_prob_certain_states(frequency_dict, condition, conditional_event):\n",
    "    # Calculate P(A | A = 0)\n",
    "    counts = {}\n",
    "    total_count = 0\n",
    "\n",
    "    for k, v in frequency_dict.items():\n",
    "        if k[0] == condition and k[1][conditional_event] == 0:\n",
    "            counts[0] = counts.get(0, 0) + v\n",
    "            total_count += v\n",
    "        if k[0] == condition and k[1][conditional_event] == 1:\n",
    "            counts[1] = counts.get(1, 0) + v\n",
    "            total_count += v\n",
    "\n",
    "    probabilities = {k: v / total_count for k, v in counts.items()}\n",
    "    prob_array = np.array(list(probabilities.values()))\n",
    "\n",
    "    return probabilities, prob_array\n",
    "\n",
    "def calculate_row_frequency_probability(AB):\n",
    "    # Calculate P(N), return (N x 2)\n",
    "    freq_prob = np.zeros((AB.shape[0], 2))\n",
    "    for i in range(AB.shape[0]):\n",
    "        freq_prob[i, 0] = np.sum(AB[i] == 0)\n",
    "        freq_prob[i, 1] = np.sum(AB[i] == 1)\n",
    "        freq_prob[i] = freq_prob[i] / np.sum(freq_prob[i])\n",
    "    return freq_prob\n",
    "\n",
    "def calculate_prob_multip_normalize_simple(A, B):\n",
    "    # Need to change to more generalized version\n",
    "    result = [A[0] * B[0], A[0] * B[1], A[1] * B[0], A[1] * B[1]]\n",
    "    sum_result = sum(result)\n",
    "    if sum_result == 0:\n",
    "        return [0, 0, 0, 0]\n",
    "    result_normalized = [x/sum_result for x in result]\n",
    "    return result_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "def calculate_states(n_nodes):\n",
    "    return np.array([[int(c) for c in bin(i)[2:].zfill(n_nodes)] for i in range(2**n_nodes)])\n",
    "\n",
    "def find_indices_zeros_ones(n_nodes, k):\n",
    "    '''Find in at k-th digit which element = 0 and = 1, return their indexes'''\n",
    "    arr = np.arange(2**n_nodes)\n",
    "    # from big endian to little endian\n",
    "    k = n_nodes - k - 1\n",
    "    # check if k-th bit is zero\n",
    "    kth_bit_zero = np.bitwise_and(np.right_shift(arr, k), 1) == 0\n",
    "    kth_bit_one = np.bitwise_and(np.right_shift(arr, k), 1) == 1\n",
    "    # return indices where k-th bit is zero and one\n",
    "    zeros = np.where(kth_bit_zero)[0]\n",
    "    ones = np.where(kth_bit_one)[0]\n",
    "    return zeros, ones\n",
    "\n",
    "def remove_node(states, i):\n",
    "    '''remove i-th node, leave remaining states'''\n",
    "    n = states.shape[1]\n",
    "    remaining_states = np.zeros((2**(n), n-1), dtype=int)\n",
    "    for j in range(n-1):\n",
    "        if j < i:\n",
    "            remaining_states[:, j] = states[:, j]\n",
    "        else:\n",
    "            remaining_states[:, j] = states[:, j+1]\n",
    "    return remaining_states\n",
    "\n",
    "def find_same_elements(arr, detect_same_array=True):\n",
    "    ''' a numpy array arr of shape (m, n) and returns a numpy array same_values of shape (n, 2) \n",
    "    where each row in same_values contains the indices of the rows in arr that have the same values in the corresponding column.\n",
    "    '''\n",
    "    if detect_same_array:\n",
    "        unique_arr, unique_idx = np.unique(arr, axis=0, return_index=True)\n",
    "        same_idxs = [[] for _ in unique_arr]\n",
    "        for i, unique_elem in enumerate(unique_arr):\n",
    "            for j, elem in enumerate(arr):\n",
    "                if np.array_equal(unique_elem, elem):\n",
    "                    same_idxs[i].append(j)\n",
    "    else:\n",
    "        unique_arr = np.unique(arr)\n",
    "        same_idxs = []\n",
    "        for elem in unique_arr:\n",
    "            idxs = np.where(arr == elem)[0]\n",
    "            same_idxs.append(idxs.tolist())\n",
    "    return same_idxs\n",
    "\n",
    "def assign_means_disconnected_node(input_array, index_array):\n",
    "    output_array = input_array.copy()\n",
    "    for indices in index_array:\n",
    "        avg = np.mean(input_array[indices])\n",
    "        for index in indices:\n",
    "            output_array[index] = avg\n",
    "    return output_array\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Disconnection\n",
      "Total Transition Matrix: \n",
      " [[0.         0.         0.         1.        ]\n",
      " [0.33333333 0.33333333 0.         0.33333333]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.16666667 0.16666667 0.33333333 0.33333333]]\n",
      "Total Conditional Frequency: \n",
      " {(0, (0.0, 0.0)): 1, (0, (1.0, 0.0)): 0, (0, (0.0, 1.0)): 1, (0, (1.0, 1.0)): 3, (1, (0.0, 0.0)): 1, (1, (1.0, 0.0)): 1, (1, (0.0, 1.0)): 0, (1, (1.0, 1.0)): 4}\n",
      "P(AB | A = 0) =  [0.2 0.  0.2 0.6]\n",
      "P(A | A = 0) =  [0.4 0.6]\n",
      "P(B | A = 0) =  [0.2 0.8]\n",
      "P(A) & P(B) = \n",
      " [[0.4 0.6]\n",
      " [0.4 0.6]]\n",
      "P(A | A = 0) * P(B) =  [0.16000000000000003, 0.24, 0.24, 0.36]\n",
      "phi_effect_A =  0.05499999999999999\n",
      "P(B | A = 0) * P(A) =  [0.08000000000000002, 0.12, 0.32000000000000006, 0.48]\n",
      "phi_effect_B =  0.15000000000000002\n",
      "All Possible States for 2 Nodes: \n",
      " [[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "\n",
      "\n",
      "Calculate average: \n",
      "\n",
      "Remove connection A - A: \n",
      "\n",
      "If we REMOVE Node A from All states, the remaining: \n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "The index of same remaining value: \n",
      " [[0, 2], [1, 3]]\n",
      "Before: P(AB | A = 0):  [0.2 0.  0.2 0.6]\n",
      "After: P(B | A = 0) * P(A) with statistically loose connection A - A:  [0.2 0.3 0.2 0.3]\n",
      "phi_effect =  0.15\n",
      "\n",
      "Remove connection A - B: \n",
      "\n",
      "If we REMOVE Node B from All states, the remaining: \n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "The index of same remaining value: \n",
      " [[0, 1], [2, 3]]\n",
      "Before: P(AB | A = 0):  [0.2 0.  0.2 0.6]\n",
      "After: P(A | A = 0) * P(B) with statistically loose connection A - B:  [0.1 0.1 0.4 0.4]\n",
      "phi_effect =  0.15\n",
      "\n",
      "Remove connection A - B and A - A: \n",
      "\n",
      "Before: P(AB | A = 0):  [0.2 0.  0.2 0.6]\n",
      "After: P(A) * P(B) with statistically loose connection A-B and A-A:  [0.25, 0.25, 0.25, 0.25]\n",
      "phi_effect =  0.175\n"
     ]
    }
   ],
   "source": [
    "# Calculate P(AB | A = 0)\n",
    "AB = np.array([[1,0,1,1,1,0,0,0,1,0,1,1,1,1,0],\n",
    "[0,0,1,1,1,1,1,0,1,0,1,0,0,1,1]])\n",
    "\n",
    "# Before \"Disconnection\"\n",
    "print(\"Before Disconnection\")\n",
    "transition_matrix, frequency = count_and_frequency_of_state_transitions(np.transpose(AB), tmp_generator(2))\n",
    "print(\"Total Transition Matrix: \\n\", frequency)\n",
    "\n",
    "# P(s | n = 0): all states given each node s = 0\n",
    "frequency_dict = count_S0_at_tplus1(AB, 0)\n",
    "print(\"Total Conditional Frequency: \\n\",frequency_dict)\n",
    "\n",
    "# P(AB | A = 0)\n",
    "probabilities, prob_array = calculate_conditional_prob_distribution(frequency_dict, 0)\n",
    "print(\"P(AB | A = 0) = \", prob_array)\n",
    "\n",
    "# P(A | A = 0)\n",
    "A_cond_probabilities, A_cond_prob_array = calculate_conditional_prob_certain_states(frequency_dict, 0, 0)\n",
    "print(\"P(A | A = 0) = \", A_cond_prob_array)\n",
    "\n",
    "# P(B | A = 0)\n",
    "B_cond_probabilities, B_cond_prob_array = calculate_conditional_prob_certain_states(frequency_dict, 0, 1)\n",
    "print(\"P(B | A = 0) = \", B_cond_prob_array)\n",
    "\n",
    "# P(A) & P(B)\n",
    "total_frequency = calculate_row_frequency_probability(AB)\n",
    "print(\"P(A) & P(B) = \\n\", total_frequency)\n",
    "\n",
    "# P(A | A = 0) * P(B)\n",
    "result_A = calculate_prob_multip_normalize_simple(A_cond_prob_array, total_frequency[1])\n",
    "print(\"P(A | A = 0) * P(B) = \", result_A)\n",
    "disconnected_average_AA = [0.25, 0.25, 0.25, 0.25]\n",
    "phi_effect_A = wasserstein_distance(disconnected_average_AA, result_A)\n",
    "print(\"phi_effect_A = \", phi_effect_A)\n",
    "\n",
    "# P(B | A = 0) * P(A)\n",
    "result_B = calculate_prob_multip_normalize_simple(B_cond_prob_array, total_frequency[0])\n",
    "print(\"P(B | A = 0) * P(A) = \",result_B)\n",
    "disconnected_average_AB = [0.25, 0.25, 0.25, 0.25]\n",
    "phi_effect_B = wasserstein_distance(disconnected_average_AB, result_B)\n",
    "print(\"phi_effect_B = \", phi_effect_B)\n",
    "\n",
    "zeros, ones = find_indices_zeros_ones(n_nodes = 2, k = 0)\n",
    "\n",
    "states = calculate_states(2)\n",
    "print(\"All Possible States for 2 Nodes: \\n\",states)\n",
    "\n",
    "print(\"\\n\\nCalculate average: \\n\")\n",
    "\n",
    "print(\"Remove connection A - A: \\n\")\n",
    "removed_states = remove_node(calculate_states(2), 0) #remove A\n",
    "print(\"If we REMOVE Node A from All states, the remaining: \\n\",removed_states) \n",
    "find_same_values_index = find_same_elements(removed_states, detect_same_array=True)\n",
    "print(\"The index of same remaining value: \\n\", find_same_values_index)\n",
    "disconnected_average_AA = assign_means_disconnected_node(prob_array, find_same_values_index)\n",
    "print(\"Before: P(AB | A = 0): \", prob_array)\n",
    "print(\"After: P(B | A = 0) * P(A) with statistically loose connection A - A: \", disconnected_average_AA)\n",
    "phi_effect_AA = wasserstein_distance(prob_array, disconnected_average_AA)\n",
    "print(\"phi_effect = \", phi_effect_AA)\n",
    "\n",
    "print(\"\\nRemove connection A - B: \\n\")\n",
    "removed_states = remove_node(calculate_states(2), 1) #remove B\n",
    "print(\"If we REMOVE Node B from All states, the remaining: \\n\",removed_states) \n",
    "find_same_values_index = find_same_elements(removed_states, detect_same_array=True)\n",
    "print(\"The index of same remaining value: \\n\", find_same_values_index)\n",
    "disconnected_average_AB = assign_means_disconnected_node(prob_array, find_same_values_index)\n",
    "print(\"Before: P(AB | A = 0): \", prob_array)\n",
    "print(\"After: P(A | A = 0) * P(B) with statistically loose connection A - B: \", disconnected_average_AB)\n",
    "phi_effect_AB = wasserstein_distance(prob_array, disconnected_average_AB)\n",
    "print(\"phi_effect = \", phi_effect_AB)\n",
    "\n",
    "print(\"\\nRemove connection A - B and A - A: \\n\")\n",
    "disconnected_average_AAB = [0.25, 0.25, 0.25, 0.25]\n",
    "print(\"Before: P(AB | A = 0): \", prob_array)\n",
    "print(\"After: P(A) * P(B) with statistically loose connection A-B and A-A: \", disconnected_average_AAB)\n",
    "phi_effect_AAB = wasserstein_distance(prob_array, disconnected_average_AAB)\n",
    "print(\"phi_effect = \", phi_effect_AAB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating a cause repertoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_and_frequency_of_state_transitions_previous(data, states):\n",
    "    # result of this == transpose of count_and_frequency_of_state_transitions\n",
    "    transition_matrix = np.zeros((len(states), len(states)))\n",
    "    for i in range(1, len(data)):\n",
    "        current_state = data[i]\n",
    "        previous_state = data[i - 1]\n",
    "        current_state_index = np.where((states == current_state).all(axis=1))[0][0]\n",
    "        previous_state_index = np.where((states == previous_state).all(axis=1))[0][0]\n",
    "        transition_matrix[current_state_index, previous_state_index] += 1\n",
    "    frequency = transition_matrix / np.sum(transition_matrix, axis=1, keepdims=True)\n",
    "\n",
    "    average = 0\n",
    "    frequency[np.isnan(frequency)] = average\n",
    "    return transition_matrix, frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_S0_at_tminus1(matrix, condition_value):\n",
    "    '''\n",
    "    Calculate Conditional Probability of P(A | s)\n",
    "    '''\n",
    "    # Initialize a dictionary to store counts for each possible state S\n",
    "    counts = {}\n",
    "    \n",
    "    # Get the number of states\n",
    "    num_nodes = matrix.shape[0]\n",
    "    possible_states = tmp_generator(num_nodes)\n",
    "    num_possible_states = possible_states.shape[0]\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_possible_states):\n",
    "            counts[(i, tuple(possible_states[j]))] = 0\n",
    "\n",
    "    # Iterate over each time step t\n",
    "    for t in range(1 , matrix.shape[1]):\n",
    "        # Get the states at time t and t+1\n",
    "        S_t = tuple(matrix[:, t])\n",
    "        S_tminus1 = tuple(matrix[:, t-1])\n",
    "\n",
    "        # Iterate over each state index i and count the number of times each possible state has a value of 0 for state i in the following time step\n",
    "        for i in range(num_nodes):\n",
    "            if S_t[i] == condition_value:\n",
    "                index = np.where((possible_states == S_tminus1).all(axis=1))[0][0]\n",
    "                counts[(i, tuple(S_tminus1))] += 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transition frequency count: \n",
      " [[0. 1. 1. 1.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 0. 1. 2.]\n",
      " [3. 1. 0. 2.]]\n",
      "Total transition frequency matrix (current<row> x past<column>): \n",
      " [[0.         0.33333333 0.33333333 0.33333333]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.         0.         0.33333333 0.66666667]\n",
      " [0.5        0.16666667 0.         0.33333333]]\n",
      "Total Conditional Frequency: \n",
      " {(0, (0.0, 0.0)): 0, (0, (1.0, 0.0)): 1, (0, (0.0, 1.0)): 2, (0, (1.0, 1.0)): 3, (1, (0.0, 0.0)): 0, (1, (1.0, 0.0)): 2, (1, (0.0, 1.0)): 1, (1, (1.0, 1.0)): 2}\n",
      "P(AB | A = 0) =  [0.         0.16666667 0.33333333 0.5       ]\n",
      "P(A | A = 0) =  [0.33333333 0.66666667]\n",
      "P(B | A = 0) =  [0.16666667 0.83333333]\n",
      "P(A) & P(B) = \n",
      " [[0.4 0.6]\n",
      " [0.4 0.6]]\n",
      "P(A | A = 0) * P(B) =  [0.13333333333333333, 0.19999999999999998, 0.26666666666666666, 0.39999999999999997]\n",
      "phi_cause_A =  0.08333333333333333\n",
      "P(B | A = 0) * P(A) =  [0.06666666666666667, 0.09999999999999999, 0.33333333333333337, 0.5]\n",
      "phi_cause_B =  0.16666666666666669\n",
      "\n",
      "\n",
      "\n",
      "Remove connection A - A: \n",
      "\n",
      "Before: P(AB(t-1) | A = 0):  [0.         0.16666667 0.33333333 0.5       ]\n",
      "After: P(B(t-1) | A = 0) * P(A) with statistically loose connection A - A:  [0.16666667 0.33333333 0.16666667 0.33333333]\n",
      "phi_cause_AA =  0.08333333333333334\n",
      "\n",
      "Remove connection A - B: \n",
      "\n",
      "Before: P(AB(t-1) | A = 0):  [0.         0.16666667 0.33333333 0.5       ]\n",
      "After: P(A(t-1) | A = 0) * P(B) with statistically loose connection A - B:  [0.08333333 0.08333333 0.41666667 0.41666667]\n",
      "phi_cause_AB =  0.08333333333333334\n",
      "\n",
      "Remove connection A - B and A - A: \n",
      "\n",
      "Before: P(AB(t-1) | A = 0):  [0.         0.16666667 0.33333333 0.5       ]\n",
      "After: P(A) * P(B) with statistically loose connection A-B and A-A:  [0.25, 0.25, 0.25, 0.25]\n",
      "phi_cause_AAB =  0.16666666666666669\n",
      "Totol small-phi cause = MAX of 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculate P(AB(t-1) | S)\n",
    "AB = np.array([[1,0,1,1,1,0,0,0,1,0,1,1,1,1,0],\n",
    "[0,0,1,1,1,1,1,0,1,0,1,0,0,1,1]])\n",
    "\n",
    "# Before \"Disconnection\"\n",
    "transition_matrix, frequency = count_and_frequency_of_state_transitions_previous(np.transpose(AB), tmp_generator(2))\n",
    "print(\"Total transition frequency count: \\n\", transition_matrix)\n",
    "print(\"Total transition frequency matrix (current<row> x past<column>): \\n\", frequency)\n",
    "frequency_dict = count_S0_at_tminus1(AB, 0)\n",
    "print(\"Total Conditional Frequency: \\n\",frequency_dict)\n",
    "\n",
    "# P(AB(t-1) | A = 0)\n",
    "probabilities, prob_array = calculate_conditional_prob_distribution(frequency_dict, 0)\n",
    "print(\"P(AB | A = 0) = \", prob_array)\n",
    "# P(A(t-1)| A = 0)\n",
    "A_cond_probabilities, A_cond_prob_array = calculate_conditional_prob_certain_states(frequency_dict, 0, 0)\n",
    "print(\"P(A | A = 0) = \", A_cond_prob_array)\n",
    "# P(B(t-1) | A = 0)\n",
    "B_cond_probabilities, B_cond_prob_array = calculate_conditional_prob_certain_states(frequency_dict, 0, 1)\n",
    "print(\"P(B | A = 0) = \", B_cond_prob_array)\n",
    "# P(A) & P(B)\n",
    "total_frequency = calculate_row_frequency_probability(AB)\n",
    "\n",
    "print(\"P(A) & P(B) = \\n\", total_frequency)\n",
    "# P(A(t-1) | A = 0) * P(B)\n",
    "result_A = calculate_prob_multip_normalize_simple(A_cond_prob_array, total_frequency[1])\n",
    "print(\"P(A | A = 0) * P(B) = \", result_A)\n",
    "disconnected_average_AA = [0.25, 0.25, 0.25, 0.25]\n",
    "phi_cause_A = wasserstein_distance(disconnected_average_AA, result_A)\n",
    "print(\"phi_cause_A = \", phi_cause_A)\n",
    "\n",
    "# P(B(t-1) | A = 0) * P(A)\n",
    "result_B = calculate_prob_multip_normalize_simple(B_cond_prob_array, total_frequency[0])\n",
    "print(\"P(B | A = 0) * P(A) = \",result_B)\n",
    "disconnected_average_AB = [0.25, 0.25, 0.25, 0.25]\n",
    "phi_cause_B = wasserstein_distance(disconnected_average_AB, result_B)\n",
    "print(\"phi_cause_B = \", phi_cause_B)\n",
    "\n",
    "\n",
    "zeros, ones = find_indices_zeros_ones(n_nodes = 2, k = 0)\n",
    "\n",
    "states = calculate_states(2)\n",
    "print(\"\\n\\n\\nRemove connection A - A: \\n\")\n",
    "removed_states = remove_node(calculate_states(2), 0) #remove A\n",
    "find_same_values_index = find_same_elements(removed_states, detect_same_array=True)\n",
    "disconnected_average_AA = assign_means_disconnected_node(prob_array, find_same_values_index)\n",
    "print(\"Before: P(AB(t-1) | A = 0): \", prob_array)\n",
    "print(\"After: P(B(t-1) | A = 0) * P(A) with statistically loose connection A - A: \", disconnected_average_AA)\n",
    "phi_cause_AA = wasserstein_distance(prob_array, disconnected_average_AA)\n",
    "print(\"phi_cause_AA = \", phi_cause_AA)\n",
    "\n",
    "print(\"\\nRemove connection A - B: \\n\")\n",
    "removed_states = remove_node(calculate_states(2), 1) #remove B\n",
    "find_same_values_index = find_same_elements(removed_states, detect_same_array=True)\n",
    "disconnected_average_AB = assign_means_disconnected_node(prob_array, find_same_values_index)\n",
    "print(\"Before: P(AB(t-1) | A = 0): \", prob_array)\n",
    "print(\"After: P(A(t-1) | A = 0) * P(B) with statistically loose connection A - B: \", disconnected_average_AB)\n",
    "phi_cause_AB = wasserstein_distance(prob_array, disconnected_average_AB)\n",
    "print(\"phi_cause_AB = \", phi_cause_AB)\n",
    "\n",
    "print(\"\\nRemove connection A - B and A - A: \\n\")\n",
    "disconnected_average_AAB = [0.25, 0.25, 0.25, 0.25] #remove AB\n",
    "print(\"Before: P(AB(t-1) | A = 0): \", prob_array)\n",
    "print(\"After: P(A) * P(B) with statistically loose connection A-B and A-A: \", disconnected_average_AAB)\n",
    "phi_cause_AAB = wasserstein_distance(prob_array, disconnected_average_AAB)\n",
    "print(\"phi_cause_AAB = \", phi_cause_AAB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximally irreducible CAUSE repertoire (MICC)\n",
      "Total small-phi of cause = MAX of 0.08333333333333333 (EMD of A-A versus A-.A), 0.16666666666666669 (EMD of A-B versus A-.B), max of [ 0.08333333333333334 , 0.08333333333333334 , 0.16666666666666669 ](EMD of A-AB)\n",
      "Total small-phi of cause =  0.16666666666666669\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximally irreducible CAUSE repertoire (MICC)\")\n",
    "print(\"Total small-phi of cause = MAX of\", phi_cause_A, \"(EMD of A-A versus A-.A),\", phi_cause_B, \"(EMD of A-B versus A-.B),\", \"max of [\", phi_cause_AA,\",\", phi_cause_AB,\",\", phi_cause_AAB,\"](EMD of A-AB)\")\n",
    "MICC = np.max([phi_cause_A, phi_cause_B, np.max([phi_cause_AA,phi_cause_AB, phi_cause_AAB])])\n",
    "print(\"Total small-phi of cause = \", MICC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximally irreducible EFFECT repertoire (MICE)\n",
      "Total small-phi of effect = MAX of 0.05499999999999999 (EMD of A-A versus A-.A), 0.15000000000000002 (EMD of A-B versus A-.B), max of [ 0.15 , 0.15 , 0.175 ](EMD of A-AB)\n",
      "Total small-phi of effect =  0.175\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximally irreducible EFFECT repertoire (MICE)\")\n",
    "print(\"Total small-phi of effect = MAX of\", phi_effect_A, \"(EMD of A-A versus A-.A),\", phi_effect_B, \"(EMD of A-B versus A-.B),\", \"max of [\", phi_effect_AA,\",\", phi_effect_AB,\",\", phi_effect_AAB,\"](EMD of A-AB)\")\n",
    "MICE = np.max([phi_effect_A, phi_effect_B, np.max([phi_effect_AA,phi_effect_AB, phi_effect_AAB])])\n",
    "print(\"Total small-phi of effect = \", MICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts of AB: min(phi cause, phi effect) =  0.16666666666666669\n"
     ]
    }
   ],
   "source": [
    "print(\"Concepts of AB: min(phi cause, phi effect) = \", min(MICE, MICC) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "255cf2a5dc0d3c92f73f8e2a747cbe0633620ba09ef09aeebb005a14c6a7f748"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
